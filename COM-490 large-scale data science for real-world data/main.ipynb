{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca27c4d-12d1-45c3-9bd6-867a46658fe6",
   "metadata": {},
   "source": [
    "# Content\n",
    "\n",
    "* ### 1 - Environment settings\n",
    "* ### 2 - Load data\n",
    "* ### 3 - Data preparation\n",
    "* ### 4 - Graph creation\n",
    "* ### 5 - Routing algorithm\n",
    "  * ### 5.1 - Helper methods\n",
    "  * ### 5.2 - Algorithm\n",
    "* ### 6 - Visualization\n",
    "    * ### 6.1 - Helper methods\n",
    "    * ### 6.2 - Visualization interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4705a63-3d02-4481-9ffd-e5ed299b34c3",
   "metadata": {},
   "source": [
    "# 1 - Environment settings "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2445a347-7a2e-4f66-a810-4a38f5311e68",
   "metadata": {},
   "source": [
    "### Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c69f6df-1450-48b9-a84e-1399c83fd35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/spark\n",
      "hadoopFSs=hdfs://iccluster059.iccluster.epfl.ch:9000\n",
      "username=valat\n",
      "group=L1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pwd\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from random import randrange\n",
    "import pyspark.sql.functions as F\n",
    "#np.bool = np.bool_\n",
    "\n",
    "\n",
    "username = pwd.getpwuid(os.getuid()).pw_name\n",
    "hadoopFS=os.getenv('HADOOP_FS', None)\n",
    "groupName = 'L1'\n",
    "\n",
    "print(os.getenv('SPARK_HOME'))\n",
    "print(f\"hadoopFSs={hadoopFS}\")\n",
    "print(f\"username={username}\")\n",
    "print(f\"group={groupName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8056864-75a3-4bd0-94a8-1fc1c310cada",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/06/01 09:32:34 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession\\\n",
    "            .builder\\\n",
    "            .appName(pwd.getpwuid(os.getuid()).pw_name)\\\n",
    "            .config('spark.ui.port', randrange(4040, 4440, 5))\\\n",
    "            .config(\"spark.executorEnv.PYTHONPATH\", \":\".join(sys.path)) \\\n",
    "            .config('spark.jars', f'{hadoopFS}/data/com-490/jars/iceberg-spark-runtime-3.5_2.13-1.6.1.jar')\\\n",
    "            .config('spark.sql.extensions', 'org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions')\\\n",
    "            .config('spark.sql.catalog.iceberg', 'org.apache.iceberg.spark.SparkCatalog')\\\n",
    "            .config('spark.sql.catalog.iceberg.type', 'hadoop')\\\n",
    "            .config('spark.sql.catalog.iceberg.warehouse', f'{hadoopFS}/data/com-490/iceberg/')\\\n",
    "            .config('spark.sql.catalog.spark_catalog', 'org.apache.iceberg.spark.SparkSessionCatalog')\\\n",
    "            .config('spark.sql.catalog.spark_catalog.type', 'hadoop')\\\n",
    "            .config('spark.sql.catalog.spark_catalog.warehouse', f'{hadoopFS}/user/{username}/assignment-3/warehouse')\\\n",
    "            .config(\"spark.sql.warehouse.dir\", f'{hadoopFS}/user/{username}/assignment-3/spark/warehouse')\\\n",
    "            .config('spark.eventLog.gcMetrics.youngGenerationGarbageCollectors', 'G1 Young Generation')\\\n",
    "            .config(\"spark.executor.memory\", \"6g\")\\\n",
    "            .config(\"spark.executor.cores\", \"4\")\\\n",
    "            .config(\"spark.executor.instances\", \"4\")\\\n",
    "            .master('yarn')\\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3b858-195a-465d-88ae-1390360a329f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48735799-689f-4829-a189-1df7f86b38c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupName='L1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a54b90-4ed9-432b-8fae-fceb991c8f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be6a4819-a0f6-4e7c-becd-17abb76d4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"pandas only supports SQLAlchemy connectable .*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e5d12ea-ddea-435f-9f71-f7ca4581aeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64 as b64\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "\n",
    "def getUsername():\n",
    "    payload = os.environ.get('EPFL_COM490_TOKEN').split('.')[1]\n",
    "    payload=payload+'=' * (4 - len(payload) % 4)\n",
    "    obj = json.loads(b64.urlsafe_b64decode(payload))\n",
    "    if (time.time() > int(obj.get('exp')) - 3600):\n",
    "        raise Exception('Your credentials have expired, please restart your Jupyter Hub server:'\n",
    "                        'File>Hub Control Panel, Stop My Server, Start My Server.')\n",
    "    time_left = int((obj.get('exp') - time.time())/3600)\n",
    "    return obj.get('sub'), time_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15f952a-5be3-4e32-9974-1631cff69922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are: valat\n",
      "credentials validity: 166 hours left.\n",
      "shared namespace is: iceberg.com490_iceberg\n",
      "your namespace is: iceberg.valat\n",
      "your group is: L1\n"
     ]
    }
   ],
   "source": [
    "username, validity_h = getUsername()\n",
    "hadoopFS = os.environ.get('HADOOP_FS')\n",
    "namespace = 'iceberg.' + username\n",
    "sharedNS = 'iceberg.com490_iceberg'\n",
    "\n",
    "if not re.search('[A-Z][0-9]', groupName):\n",
    "    raise Exception('Invalid group name {groupName}')\n",
    "\n",
    "print(f\"you are: {username}\")\n",
    "print(f\"credentials validity: {validity_h} hours left.\")\n",
    "print(f\"shared namespace is: {sharedNS}\")\n",
    "print(f\"your namespace is: {namespace}\")\n",
    "print(f\"your group is: {groupName}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c56cae-55c4-4b56-b77a-2088074ae957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse URL: https://iccluster028.iccluster.epfl.ch:8443/\n",
      "Connected!\n"
     ]
    }
   ],
   "source": [
    "import trino\n",
    "from contextlib import closing\n",
    "from urllib.parse import urlparse\n",
    "from trino.dbapi import connect\n",
    "from trino.auth import BasicAuthentication, JWTAuthentication\n",
    "\n",
    "trinoAuth = JWTAuthentication(os.environ.get('EPFL_COM490_TOKEN'))\n",
    "trinoUrl  = urlparse(os.environ.get('TRINO_URL'))\n",
    "Query=[]\n",
    "\n",
    "print(f\"Warehouse URL: {trinoUrl.scheme}://{trinoUrl.hostname}:{trinoUrl.port}/\")\n",
    "\n",
    "conn = connect(\n",
    "    host=trinoUrl.hostname,\n",
    "    port=trinoUrl.port,\n",
    "    auth=trinoAuth,\n",
    "    http_scheme=trinoUrl.scheme,\n",
    "    verify=True\n",
    ")\n",
    "\n",
    "print('Connected!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d74e7c1c-73aa-4a28-8753-718df72e4519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1b12e-551b-4354-9b30-c0c292514140",
   "metadata": {},
   "source": [
    "# 2 - Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58021cb7-43dd-4ae3-8aae-de7f36ed6bc7",
   "metadata": {},
   "source": [
    "### Delay prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05a20e4d-755d-4062-9cbc-e7fbdd11b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.pipeline import PipelineModel\n",
    "\n",
    "model_path = f\"{hadoopFS}/user/com-490/group/{groupName}/delay_model\"\n",
    "delay_model = PipelineModel.load(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d99c1-6cd8-4a5b-98be-31f5fd41147c",
   "metadata": {},
   "source": [
    "### Historical average delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6fdd5db-cab6-49fa-9382-763044dfe342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "avg_delay_by_hour = spark.read.csv(f\"{hadoopFS}/user/com-490/group/{groupName}/avg_delay_by_hour.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5eaa9ad9-f0f8-4e48-8e32-584aaae573d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_delay_by_bpuic = spark.read.csv(f\"{hadoopFS}/user/com-490/group/{groupName}/avg_delay_by_bpuic.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0e3eb6-7a7f-40f3-8c23-459348a594e8",
   "metadata": {},
   "source": [
    "### Stop times\n",
    "It contains the stop times and weekdays of trips (trip_id) servicing stops found previously in the selected region(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "085d1534-ff3b-475c-b4c5-c5cc5a0fe71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_stop_stimes = f\"{hadoopFS}/user/com-490/group/{groupName}/sbb_stop_times_selected_regions/data\"\n",
    "spark_sbb_stop_times_region = spark.read.parquet(path_stop_stimes)\n",
    "\n",
    "sbb_stop_times_region = spark_sbb_stop_times_region.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3dfd0b-53aa-4fb6-a5e5-59775c8e0e56",
   "metadata": {},
   "source": [
    "### Stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16c12945-13d1-4feb-8780-3e8bd7999522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_stops = f\"{hadoopFS}/user/com-490/group/{groupName}/sbb_stops_selected_regions/data\"\n",
    "spark_sbb_stops_region = spark.read.parquet(path_stops)\n",
    "sbb_stops_region = spark_sbb_stops_region.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abd1aab-e115-44c4-b056-0856855b3d57",
   "metadata": {},
   "source": [
    "### Transfers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69426bd-5545-4bbb-b781-9a4fdc311673",
   "metadata": {},
   "source": [
    "Contains the stop times between two direct transfers (same lat/lon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "853b3165-9313-4eee-8574-3ccff0ec6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_df = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {sharedNS}.sbb_transfers\n",
    "\"\"\"\n",
    "transfers_df = pd.read_sql(query_df, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d840c8-f725-4bba-b908-62b474cdfa56",
   "metadata": {},
   "source": [
    "### Walking distance stops\n",
    "Contains stops within 500m of each other, as directed pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65f86bac-2a1e-4e04-a036-8413a070b5e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "path_stops_to_stops = f\"{hadoopFS}/user/com-490/group/{groupName}/sbb_stops_to_stops_selected_regions/data\"\n",
    "spark_sbb_stops_to_stops_region = spark.read.parquet(path_stops_to_stops)\n",
    "sbb_stops_to_stops_df = spark_sbb_stops_to_stops_region.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02443ab7-481a-49d0-b9e4-91c0cc1e6556",
   "metadata": {},
   "source": [
    "### Routes and trips \n",
    "Used in the visualizations to have the names of routes. \n",
    "This takes a long time to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b5124b5-8832-484b-a5ec-ae57fce43622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>route_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_long_name</th>\n",
       "      <th>route_desc</th>\n",
       "      <th>route_type</th>\n",
       "      <th>pub_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91-10-A-j21-1</td>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>T</td>\n",
       "      <td>900</td>\n",
       "      <td>2021-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>91-10-B-j21-1</td>\n",
       "      <td>06____</td>\n",
       "      <td>S10</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>109</td>\n",
       "      <td>2021-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>91-10-C-j21-1</td>\n",
       "      <td>11</td>\n",
       "      <td>RE10</td>\n",
       "      <td></td>\n",
       "      <td>RE</td>\n",
       "      <td>106</td>\n",
       "      <td>2021-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91-10-D-j21-1</td>\n",
       "      <td>11</td>\n",
       "      <td>S10</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>109</td>\n",
       "      <td>2021-10-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91-10-F-j21-1</td>\n",
       "      <td>78</td>\n",
       "      <td>S10</td>\n",
       "      <td></td>\n",
       "      <td>S</td>\n",
       "      <td>109</td>\n",
       "      <td>2021-10-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        route_id agency_id route_short_name route_long_name route_desc  \\\n",
       "0  91-10-A-j21-1        37               10                          T   \n",
       "1  91-10-B-j21-1    06____              S10                          S   \n",
       "2  91-10-C-j21-1        11             RE10                         RE   \n",
       "3  91-10-D-j21-1        11              S10                          S   \n",
       "4  91-10-F-j21-1        78              S10                          S   \n",
       "\n",
       "   route_type    pub_date  \n",
       "0         900  2021-10-20  \n",
       "1         109  2021-10-20  \n",
       "2         106  2021-10-20  \n",
       "3         109  2021-10-20  \n",
       "4         109  2021-10-20  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM {sharedNS}.sbb_routes\n",
    "    LIMIT 5\n",
    "\"\"\"\n",
    "pd.read_sql(query_df, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79a1a86f-18cb-4416-80ea-d9e5b781184d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.TA.92-690-j21-1.21.R</td>\n",
       "      <td>92-690-j21-1</td>\n",
       "      <td>690</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56.TA.92-690-j21-1.25.R</td>\n",
       "      <td>92-690-j21-1</td>\n",
       "      <td>690</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63.TA.92-691-j21-1.5.R</td>\n",
       "      <td>92-691-j21-1</td>\n",
       "      <td>691</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32.TA.92-693-j21-1.3.R</td>\n",
       "      <td>92-693-j21-1</td>\n",
       "      <td>693</td>\n",
       "      <td>Bus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36.TA.92-693-j21-1.3.R</td>\n",
       "      <td>92-693-j21-1</td>\n",
       "      <td>693</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   trip_id      route_id route_short_name route_desc\n",
       "0  47.TA.92-690-j21-1.21.R  92-690-j21-1              690        Bus\n",
       "1  56.TA.92-690-j21-1.25.R  92-690-j21-1              690        Bus\n",
       "2   63.TA.92-691-j21-1.5.R  92-691-j21-1              691          B\n",
       "3   32.TA.92-693-j21-1.3.R  92-693-j21-1              693        Bus\n",
       "4   36.TA.92-693-j21-1.3.R  92-693-j21-1              693          B"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_df = f\"\"\"\n",
    "    SELECT distinct t.trip_id, r.route_id, r.route_short_name, r.route_desc\n",
    "    FROM {sharedNS}.sbb_trips t\n",
    "    INNER JOIN {sharedNS}.sbb_routes r on r.route_id = t.route_id\n",
    "    \"\"\"\n",
    "\n",
    "trip_names_df = pd.read_sql(query_df, conn)\n",
    "trip_names_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2244fc3f-142c-4d45-b582-55f519ea91f2",
   "metadata": {},
   "source": [
    "# 3 - Data preparation \n",
    "\n",
    "### Filter the stops\n",
    "We only want to consider journeys at reasonable hours of the day, and on a typical business day, and assuming a recent schedule. So, we only keep stops that are : \n",
    "- from the selected region(s)\n",
    "- operating on a weekday\n",
    "- between EARLIEST_TIME and LATEST_TIME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca4fe1c0-91b4-49e0-b44b-3fc570790348",
   "metadata": {},
   "outputs": [],
   "source": [
    "EARLIEST_TIME = '08:00:00'\n",
    "LATEST_TIME = '20:00:00'\n",
    "\n",
    "weekdays = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday']\n",
    "sbb_stops_region_filtered = sbb_stop_times_region[sbb_stop_times_region[weekdays].any(axis=1)] \\\n",
    "    [\n",
    "        (sbb_stop_times_region['departure_time'] >= EARLIEST_TIME) &\n",
    "        (sbb_stop_times_region['departure_time'] <= LATEST_TIME) &\n",
    "        (sbb_stop_times_region['arrival_time'] >= EARLIEST_TIME) &\n",
    "        (sbb_stop_times_region['arrival_time'] <= LATEST_TIME) \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a9e80c1f-3065-4171-a6db-09786dba6220",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbb_stops_region_filtered = sbb_stops_region_filtered.merge(sbb_stops_region, left_on='stop_id', right_on= 'stop_id_cleaned', how='left').merge(trip_names_df, on = 'trip_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598819f-a2b8-4a4a-b805-526387e8a127",
   "metadata": {},
   "source": [
    "### Filter trip_names_df \n",
    "We only keep trips from our selected region(s). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf3a4676-03c3-458b-9faf-89b45787b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_trips = set(sbb_stops_region_filtered['trip_id'])\n",
    "trip_names_df = trip_names_df[trip_names_df['trip_id'].isin(region_trips)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6787cf4-5e35-40f6-ad5f-4a8783ae57df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "      <th>stop_id_cleaned</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.TA.96-240-j24-1.2.R</td>\n",
       "      <td>8570064</td>\n",
       "      <td>19:50:00</td>\n",
       "      <td>19:50:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8570064</td>\n",
       "      <td>Cheseaux-sur-L., Pâquis</td>\n",
       "      <td>46.586866711232</td>\n",
       "      <td>6.603785149067</td>\n",
       "      <td>96-240-j24-1</td>\n",
       "      <td>425</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.TA.96-240-j24-1.2.R</td>\n",
       "      <td>8570063</td>\n",
       "      <td>19:49:00</td>\n",
       "      <td>19:49:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8570063</td>\n",
       "      <td>Cheseaux-sur-L., gare</td>\n",
       "      <td>46.584168733670</td>\n",
       "      <td>6.605114655688</td>\n",
       "      <td>96-240-j24-1</td>\n",
       "      <td>425</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.TA.92-54-B-j24-1.4.R</td>\n",
       "      <td>8593816</td>\n",
       "      <td>18:35:00</td>\n",
       "      <td>18:35:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>8593816</td>\n",
       "      <td>Crissier, Marcolet</td>\n",
       "      <td>46.546932815805</td>\n",
       "      <td>6.574868380067</td>\n",
       "      <td>92-54-B-j24-1</td>\n",
       "      <td>54</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   trip_id  stop_id departure_time arrival_time  monday  \\\n",
       "0   31.TA.96-240-j24-1.2.R  8570064       19:50:00     19:50:00    True   \n",
       "1   31.TA.96-240-j24-1.2.R  8570063       19:49:00     19:49:00    True   \n",
       "2  95.TA.92-54-B-j24-1.4.R  8593816       18:35:00     18:35:00    True   \n",
       "\n",
       "   tuesday  wednesday  thursday  friday  saturday  sunday stop_id_cleaned  \\\n",
       "0     True       True      True    True      True    True         8570064   \n",
       "1     True       True      True    True      True    True         8570063   \n",
       "2     True       True      True    True      True    True         8593816   \n",
       "\n",
       "                 stop_name         stop_lat        stop_lon       route_id  \\\n",
       "0  Cheseaux-sur-L., Pâquis  46.586866711232  6.603785149067   96-240-j24-1   \n",
       "1    Cheseaux-sur-L., gare  46.584168733670  6.605114655688   96-240-j24-1   \n",
       "2       Crissier, Marcolet  46.546932815805  6.574868380067  92-54-B-j24-1   \n",
       "\n",
       "  route_short_name route_desc  \n",
       "0              425          B  \n",
       "1              425          B  \n",
       "2               54          B  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbb_stops_region_filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69036f12-9c53-47b4-975f-35f12b99564d",
   "metadata": {},
   "source": [
    "### List of unique stop names\n",
    "To use later for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32917fb6-4105-4289-bc78-7a18c6d6accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_stop_names = sbb_stops_region_filtered['stop_name'].drop_duplicates().tolist()\n",
    "unique_stop_names = sorted(unique_stop_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424b2a05-a41a-48d8-931e-c71f4b1ece71",
   "metadata": {},
   "source": [
    "### Filter the transfers\n",
    "- Keep only the transfers that are within the selected region. \n",
    "- Do this by keeping only (from_stop_id, to_stop_id) in sbb_stops_region_filtered.stop_id\n",
    "- keep only the most recent pub_date per (from_stop_id, to_stop_id) pair in transfers_df_filtered\n",
    "- convert to minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b10e9fe-db3f-482a-abfc-d01804826200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the set of valid stop_ids\n",
    "valid_stops = set(sbb_stops_region_filtered['stop_id'])\n",
    "\n",
    "# Filter sbb_transfers\n",
    "transfers_df_filtered = transfers_df[\n",
    "    transfers_df['from_stop_id'].isin(valid_stops) &\n",
    "    transfers_df['to_stop_id'].isin(valid_stops)\n",
    "]\n",
    "\n",
    "# Find the index of the most recent pub_date per (from_stop_id, to_stop_id) pair\n",
    "idx = transfers_df_filtered.groupby(['from_stop_id', 'to_stop_id'])['pub_date'].idxmax()\n",
    "transfers_df_filtered = transfers_df_filtered.loc[idx].reset_index(drop=True)\n",
    "\n",
    "# Convert to min\n",
    "transfers_df_filtered['min_transfer_time'] = transfers_df_filtered['min_transfer_time'] / 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88bbee0-3aa3-48b8-b03e-7cd540b5c077",
   "metadata": {},
   "source": [
    "### Create the walk transfers\n",
    "- We use table sbb_stops_to_stops_df that contains all stops that are within 500m walking distance between each other.\n",
    "- Add a column _distance_ that estimates walking time between points\n",
    "- I don't remove stop pairs from sbb_stops_to_stops_df_filtered that are already present in transfers_df_filtered, so there may be duplicate edges for walking transfers, but the algo will take the min anyways\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0147525-7938-48a7-8237-34b1c8d7a3ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1453504/3885168292.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sbb_stops_to_stops_df_filtered['duration'] = req_walking_time(sbb_stops_to_stops_df_filtered['distance'])\n"
     ]
    }
   ],
   "source": [
    "def req_walking_time(distance):\n",
    "    # In minutes - to be consistent with other times\n",
    "    # For walking speed we use assumption of 50m/min\n",
    "    # We don't add an additional 2min for transfer within same location\n",
    "    walking_time = distance / 50 \n",
    "    \n",
    "    return walking_time\n",
    "\n",
    "sbb_stops_to_stops_df_filtered = sbb_stops_to_stops_df[\n",
    "    sbb_stops_to_stops_df['stop_id_a'].isin(valid_stops) &\n",
    "    sbb_stops_to_stops_df['stop_id_a'].isin(valid_stops)\n",
    "]\n",
    "\n",
    "sbb_stops_to_stops_df_filtered['duration'] = req_walking_time(sbb_stops_to_stops_df_filtered['distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "debff21f-87c0-4ecb-9101-c10b60e6afa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_id_a</th>\n",
       "      <th>stop_id_b</th>\n",
       "      <th>distance</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1894</th>\n",
       "      <td>8592086</td>\n",
       "      <td>8595933</td>\n",
       "      <td>478.711259</td>\n",
       "      <td>9.574225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>8592086</td>\n",
       "      <td>8501075</td>\n",
       "      <td>276.230739</td>\n",
       "      <td>5.524615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>8592086</td>\n",
       "      <td>8591986</td>\n",
       "      <td>113.884055</td>\n",
       "      <td>2.277681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>8592086</td>\n",
       "      <td>8592061</td>\n",
       "      <td>280.372377</td>\n",
       "      <td>5.607448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stop_id_a stop_id_b    distance  duration\n",
       "1894   8592086   8595933  478.711259  9.574225\n",
       "2147   8592086   8501075  276.230739  5.524615\n",
       "2819   8592086   8591986  113.884055  2.277681\n",
       "2878   8592086   8592061  280.372377  5.607448"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbb_stops_to_stops_df_filtered[sbb_stops_to_stops_df_filtered['stop_id_a'] == '8592086']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7f462-d745-4ab3-be56-524132f0a9df",
   "metadata": {},
   "source": [
    "# 4 - Graph creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b891387d-21e3-47b6-b6be-e5d2a70de0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>monday</th>\n",
       "      <th>tuesday</th>\n",
       "      <th>wednesday</th>\n",
       "      <th>thursday</th>\n",
       "      <th>friday</th>\n",
       "      <th>saturday</th>\n",
       "      <th>sunday</th>\n",
       "      <th>stop_id_cleaned</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_lat</th>\n",
       "      <th>stop_lon</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_short_name</th>\n",
       "      <th>route_desc</th>\n",
       "      <th>dep_minutes</th>\n",
       "      <th>arr_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>137476</th>\n",
       "      <td>1.TA.91-m2-j24-1.1.H</td>\n",
       "      <td>8592050</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8592050</td>\n",
       "      <td>Lausanne, gare</td>\n",
       "      <td>46.517201094384</td>\n",
       "      <td>6.632118013132</td>\n",
       "      <td>91-m2-j24-1</td>\n",
       "      <td>m2</td>\n",
       "      <td>M</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137477</th>\n",
       "      <td>1.TA.91-m2-j24-1.1.H</td>\n",
       "      <td>8592050</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8592050</td>\n",
       "      <td>Lausanne, gare</td>\n",
       "      <td>46.517602899357</td>\n",
       "      <td>6.629656629253</td>\n",
       "      <td>91-m2-j24-1</td>\n",
       "      <td>m2</td>\n",
       "      <td>M</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137478</th>\n",
       "      <td>1.TA.91-m2-j24-1.1.H</td>\n",
       "      <td>8592050</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>16:59:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>8592050</td>\n",
       "      <td>Lausanne, gare</td>\n",
       "      <td>46.517201094384</td>\n",
       "      <td>6.632118013132</td>\n",
       "      <td>91-m2-j24-1</td>\n",
       "      <td>m2</td>\n",
       "      <td>M</td>\n",
       "      <td>1019.0</td>\n",
       "      <td>1019.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trip_id  stop_id departure_time arrival_time  monday  \\\n",
       "137476  1.TA.91-m2-j24-1.1.H  8592050       16:59:00     16:59:00    True   \n",
       "137477  1.TA.91-m2-j24-1.1.H  8592050       16:59:00     16:59:00    True   \n",
       "137478  1.TA.91-m2-j24-1.1.H  8592050       16:59:00     16:59:00    True   \n",
       "\n",
       "        tuesday  wednesday  thursday  friday  saturday  sunday  \\\n",
       "137476     True       True      True    True     False   False   \n",
       "137477     True       True      True    True     False   False   \n",
       "137478     True       True      True    True     False   False   \n",
       "\n",
       "       stop_id_cleaned       stop_name         stop_lat        stop_lon  \\\n",
       "137476         8592050  Lausanne, gare  46.517201094384  6.632118013132   \n",
       "137477         8592050  Lausanne, gare  46.517602899357  6.629656629253   \n",
       "137478         8592050  Lausanne, gare  46.517201094384  6.632118013132   \n",
       "\n",
       "           route_id route_short_name route_desc  dep_minutes  arr_minutes  \n",
       "137476  91-m2-j24-1               m2          M       1019.0       1019.0  \n",
       "137477  91-m2-j24-1               m2          M       1019.0       1019.0  \n",
       "137478  91-m2-j24-1               m2          M       1019.0       1019.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import time, datetime\n",
    "from queue import PriorityQueue\n",
    "\n",
    "'''\n",
    "Convert a given time t to seconds from midnight.\n",
    "Can accept 3 different forma tof time : string ('HH:MM:SS'), datetime and time.\n",
    "'''\n",
    "def time_to_minutes(t):\n",
    "    # For 'HH:MM:SS' format (string)\n",
    "    if isinstance(t, str):\n",
    "        h, m, s = map(int, t.split(':'))\n",
    "    # For time and datetime format\n",
    "    elif isinstance(t, datetime.time) or isinstance(t, datetime.datetime):\n",
    "        h, m, s = t.hour, t.minute, t.second\n",
    "    else:\n",
    "        raise ValueError(\"Input should be a string, datetime.time, or datetime.datetime object.\")\n",
    "    \n",
    "    return h * 60 + m + s / 60\n",
    "\n",
    "sbb_stops_region_filtered['dep_minutes'] = sbb_stops_region_filtered['departure_time'].apply(time_to_minutes)\n",
    "sbb_stops_region_filtered['arr_minutes'] = sbb_stops_region_filtered['arrival_time'].apply(time_to_minutes)\n",
    "\n",
    "sbb_stops_region_filtered = sbb_stops_region_filtered.sort_values(by=['trip_id', 'dep_minutes'])\n",
    "sbb_stops_region_filtered.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed557e-c748-4dec-8d6a-d7e18ba411eb",
   "metadata": {},
   "source": [
    "### Build the graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fa5ded2-c660-4bb3-9900-5054ab2d5c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {}\n",
    "\n",
    "# Group by trip_id and build the graph\n",
    "for trip_id, group in sbb_stops_region_filtered.groupby('trip_id'):\n",
    "    # for each trip, get the stops and their characteristics\n",
    "    trip_stops = group[['stop_id', 'dep_minutes', 'arr_minutes']].values\n",
    "\n",
    "    # construct the edges as described above stop i -> list of (dep time from i, arr time to j, stop j)\n",
    "    for i in range(len(trip_stops)-1):\n",
    "        from_stop, dep_time_min, _ = trip_stops[i]\n",
    "        to_stop, _, arr_time_min = trip_stops[i + 1]\n",
    "\n",
    "        # Store edge in graph\n",
    "        if from_stop not in graph:\n",
    "            graph[from_stop] = []\n",
    "        graph[from_stop].append((dep_time_min, arr_time_min, to_stop, trip_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b882c361-d56f-46f9-8d38-44f5d2a22ba8",
   "metadata": {},
   "source": [
    "### Turn the graph into a network graph, and add more edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0583f5a-9a1e-4f3c-b955-4819f91c013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directed graph\n",
    "G = nx.MultiDiGraph()\n",
    "\n",
    "# 1. Add nodes from df\n",
    "stop_ids = sbb_stops_region_filtered['stop_id'].unique()\n",
    "G.add_nodes_from(stop_ids)\n",
    "\n",
    "# 2. Add edges from the `graph` dictionary\n",
    "# graph['from_stop_id'] = [(dep_time_min, arr_time_min, to_stop_id, trip_id), ...]\n",
    "for from_stop_id, edges in graph.items():\n",
    "    for dep_time_min, arr_time_min, to_stop_id, trip_id in edges:\n",
    "        G.add_edge(\n",
    "            from_stop_id,\n",
    "            to_stop_id,\n",
    "            dep_time_min=dep_time_min,\n",
    "            arr_time_min=arr_time_min,\n",
    "            trip_id=trip_id,\n",
    "            edge_type='transit'\n",
    "        )\n",
    "        \n",
    "# 3. Add transfer edges (e.g. walking connections) between stops, separate from vehicle-based edges.\n",
    "for _, row in transfers_df_filtered.iterrows():\n",
    "    from_stop = row['from_stop_id']\n",
    "    to_stop = row['to_stop_id']\n",
    "    transfer_type = row['transfer_type']\n",
    "    min_transfer_time = row['min_transfer_time']\n",
    "    pub_date = row.get('pub_date')  # optional\n",
    "\n",
    "    # Add the transfer edge with attributes\n",
    "    G.add_edge(\n",
    "        from_stop,\n",
    "        to_stop,\n",
    "        transfer_type=transfer_type,\n",
    "        min_transfer_time=min_transfer_time,\n",
    "        pub_date=pub_date,\n",
    "        edge_type='transfer'  # distinguish from vehicle-based edges\n",
    "    )\n",
    "\n",
    "# 4. Add walking edges between stops that are < 500m from each other.\n",
    "for _, row in sbb_stops_to_stops_df_filtered.iterrows():\n",
    "    from_stop = row['stop_id_a']\n",
    "    to_stop = row['stop_id_b']\n",
    "    distance = row['distance']\n",
    "    duration = row['duration']\n",
    "\n",
    "    G.add_edge(\n",
    "        from_stop,\n",
    "        to_stop,\n",
    "        distance=distance,\n",
    "        duration=duration,\n",
    "        edge_type='walking'\n",
    "    )\n",
    "\n",
    "# Reverse the graph to make it easier to traverse backwards\n",
    "G = G.reverse(copy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364fe3c-ae3b-4bef-9298-c033a72b72ec",
   "metadata": {},
   "source": [
    "# 5 - Routing algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951cb088-d212-4d56-9e5b-0ea331553ec2",
   "metadata": {},
   "source": [
    "## 5.1 - Helper methods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b79d83-bf30-4ebe-87bd-9b07c7f674ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import heappush, heappop\n",
    "from itertools import count\n",
    "import datetime\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0b2ee480-ece3-4f25-aeb7-75566b1244c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Methods to get score of a path. Score defined by departure time.\n",
    "'''\n",
    "def score_path_by_latest_departure(path):\n",
    "    # In reversed route, the first node is destination, last is origin\n",
    "    dep_time = path[-1]['dep_time_min']\n",
    "    return dep_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6f6801b8-2fe2-4cfb-a4bb-4c240f8dd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given a leg (= from node, to node, departute time, arrival time, trip_id and type of trip):\n",
    "Build the corresponding feature vector to be given to the delay model\n",
    "The vector must have the following columns :  rain (1 if rainy day, 0 otherwise), hour, day_of_week, avg_delay_hour, avg_delay_bpuic\n",
    "'''\n",
    "def build_features_from_leg(leg, weather_condition, date_of_the_day):\n",
    "    rain = 0 if weather_condition=='Clear' else 1\n",
    "    hour = date_of_the_day.hour\n",
    "    \n",
    "    day_of_week = date_of_the_day.weekday() # Monday = 0, Sunday = 6\n",
    "\n",
    "    # Get avg_delay_hour for the current hour\n",
    "    filtered_data = avg_delay_by_hour[avg_delay_by_hour[\"hour\"] == hour]\n",
    "    avg_delay_hour_row = filtered_data.select(\"avg_delay_hour\").first()\n",
    "    avg_delay_hour = avg_delay_hour_row[0] if avg_delay_hour_row else 0.0  # Default to 0 if no data\n",
    "\n",
    "    # Get avg_delay_bpuic for the destination stop\n",
    "    bpuic = leg['to']\n",
    "    filtered_data = avg_delay_by_bpuic[avg_delay_by_bpuic[\"bpuic\"] == bpuic]\n",
    "    avg_delay_bpuic_row = filtered_data.select(\"avg_delay_bpuic\").first()\n",
    "    avg_delay_bpuic = avg_delay_bpuic_row[0] if avg_delay_bpuic_row else 0.0  # Default to 0 if no data\n",
    "\n",
    "\n",
    "    # Check, in case of nan (should not have but if does, put to 0)\n",
    "    if pd.isna(avg_delay_hour) or pd.isna(avg_delay_bpuic):\n",
    "        print(\"Invalid data found: avg_delay_hour or avg_delay_bpuic is NaN or None.\")\n",
    "        avg_delay_hour = 0.0\n",
    "        avg_delay_bpuic = 0.0\n",
    "\n",
    "    # Convert the features to a list of values\n",
    "    feature_list = [\n",
    "        rain,\n",
    "        hour,\n",
    "        day_of_week,\n",
    "        avg_delay_hour,\n",
    "        avg_delay_bpuic\n",
    "    ]\n",
    "    return feature_list\n",
    "\n",
    "\n",
    "def get_confidence(path, model, weather_condition, date_of_the_day):\n",
    "    \"\"\"\n",
    "    Get the confidence level for a given path by evaluating each leg (if it's a transit leg).\n",
    "   \n",
    "    Parameters:\n",
    "    - path (list): List of leg dictionaries representing the path.\n",
    "    - model (PipelineModel): The trained model for prediction.\n",
    "    - weather_condition (str): Weather condition ('Clear' or 'Rain').\n",
    "    - date_of_the_day (datetime): The date of the day for feature extraction.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The overall confidence for the path.\n",
    "    \"\"\"\n",
    "    \n",
    "    feature_list = []\n",
    "    \n",
    "    for leg in path:\n",
    "        if leg['type'] == 'transit':\n",
    "            # Get leg's feature and append it to feature_list\n",
    "            feature_vector = build_features_from_leg(leg, weather_condition, date_of_the_day) \n",
    "            feature_list.append(feature_vector)\n",
    "    \n",
    "    if not feature_list:\n",
    "        return 1.0  # Assume 100% confidence if no transit legs\n",
    "    \n",
    "    # Now create a DataFrame for all features\n",
    "    features_df = spark.createDataFrame(feature_list, ['rain', 'hour', 'day_of_week', 'avg_delay_hour', 'avg_delay_bpuic'])\n",
    "\n",
    "    # Use VectorAssembler to convert to vector format for ML\n",
    "    assembler = VectorAssembler(inputCols=['rain', 'hour', 'day_of_week', 'avg_delay_hour', 'avg_delay_bpuic'], outputCol=\"features\")\n",
    "    feature_vector_df = assembler.transform(features_df)\n",
    "\n",
    "    # Transform all features at once\n",
    "    predictions = model.transform(feature_vector_df)\n",
    "\n",
    "    # Extract probabilities for class 1 (probability of delay) for all legs at once\n",
    "    get_prob_class1 = udf(lambda prob: float(prob[1]), DoubleType())\n",
    "    predictions_with_probs = predictions.withColumn(\"probability_class_1\", get_prob_class1(\"probability\"))\n",
    "    # Extract the confidence for each leg and calculate overall confidence\n",
    "    confidences = predictions_with_probs.select(\"probability_class_1\").rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "    conf = np.prod(confidences)\n",
    "    conf = 1 - conf # get proba of confidence (not delayed = 1 - delayed)\n",
    "    conf = conf*100 # put it in %, as it will be compared with Q = 80 (for example)\n",
    "    return conf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ac3e608-58db-4ea5-9423-81083d3737a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Helper class to store top k paths'''\n",
    "class TopKPathsPerNode:\n",
    "    '''\n",
    "    k: how many best paths to keep per node\n",
    "    score_fn: function that takes a path and returns a number (higher = better)\n",
    "    confidence_fn: function that takes a path and returns a float in [0,1]\n",
    "    Q: the minimum acceptable confidence threshold\n",
    "    rain : boolean, True if the day considered is a rainy day (used for the delay prediction model)\n",
    "    '''\n",
    "    def __init__(self, k, score_fn, confidence_fn, Q, delay_model, weather_condition, date_of_the_day):\n",
    "        self.k = k\n",
    "        self.score_fn = score_fn\n",
    "        self.confidence_fn = confidence_fn\n",
    "        self.Q = Q\n",
    "        self.weather_condition = weather_condition\n",
    "        self.delay_model = delay_model\n",
    "        self.date_of_the_day = date_of_the_day\n",
    "        self.paths = {}  \n",
    "        # Dictionnary paths has structure : node_id -> list of (score, path, key, confidence) ; key is used to check for similar paths. \n",
    "        # For a path x : {'from': 'A', 'to': 'B', 'dep_time_min': 600, 'arr_time_min': 610, 'trip_id': 'X'},{'from': 'B', 'to': 'C', 'dep_time_min': 615, 'arr_time_min': 630, 'trip_id': 'Y'}\n",
    "        # -> the key of path x is (('A','B',600, 610), ('B','C',615, 630))\n",
    "\n",
    "\n",
    "    '''\n",
    "    Given a node and a path, add this path to the paths directory at entry node. Add the path only if : \n",
    "        - Not similar to a path already stored. Similar is defined by same key (i.e., if has the same stops and same departure/arrival times)\n",
    "        - Its confidence level is above Q\n",
    "    Then, re sort the list of path related to the node, based on score_fn, and keep only the k tops\n",
    "    '''\n",
    "    def add_path(self, node, path):\n",
    "        key_new = tuple((leg['from'], leg['to'], leg['dep_time_min'], leg['arr_time_min']) for leg in path)\n",
    "        \n",
    "        # Check for duplicates, if yes skip the path\n",
    "        if node in self.paths:\n",
    "            existing_keys = [entry[2] for entry in self.paths[node]] # list of each already present path's key \n",
    "            if key_new in existing_keys:\n",
    "                return \n",
    "\n",
    "        # Get confidence level, if too low, skip the path\n",
    "        confidence = self.confidence_fn(path, model=self.delay_model, weather_condition=self.weather_condition, date_of_the_day = self.date_of_the_day)\n",
    "        if confidence < self.Q:\n",
    "            return  \n",
    "\n",
    "        # Get score\n",
    "        score = self.score_fn(path)\n",
    "        # Add path to list of path for given node\n",
    "        if node not in self.paths:\n",
    "            self.paths[node] = [(score, path, key_new, confidence)]\n",
    "        else:\n",
    "            self.paths[node].append((score, path, key_new, confidence))\n",
    "            # Keep only top-k (sorted by score descending)\n",
    "            self.paths[node] = sorted(self.paths[node], key=lambda x: -x[0])[:self.k]\n",
    "\n",
    "            \n",
    "    '''\n",
    "    Given a node, get the k top paths\n",
    "    '''\n",
    "    def get_k_top_paths(self, node):\n",
    "        return [(p, conf) for (_, p, _, conf) in self.paths.get(node, [])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600277db-4d50-43e1-900a-eb15c4fbc1ae",
   "metadata": {},
   "source": [
    "## 5.2 - Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a43a561-f8e7-4d9a-a38f-8740841eaa92",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Routing algorithm : reverse search algorithm to find top-k paths from a start node to a target node.\n",
    "    - Explores the graph backwards from the target to compute valid paths arriving before latest_arrival_time and starting at start_node.\n",
    "    - Keeps at most k best paths per node (best is based on latest departure time).\n",
    "    - Filters paths using a confidence function (confidence is given by the pretrained ML model).\n",
    "    - Limits exploration to expand_max expansions per node to control runtime.\n",
    "\n",
    " Returns:\n",
    "    TopKPathsPerNode object with robust path options to each node.\n",
    "'''\n",
    "def reverse_routing_algo_top_k(G_rev, start_stop, target_stop, latest_arrival_time, score_fn, confidence_fn,  Q, delay_model, weather_condition, k=5, expand_max=10):\n",
    "    \n",
    "    latest_arrival_time_min = time_to_minutes(latest_arrival_time)\n",
    "    \n",
    "    top_k_paths = TopKPathsPerNode(k, score_fn, confidence_fn, Q, delay_model=delay_model, \n",
    "                                   weather_condition=weather_condition, date_of_the_day=latest_arrival_time)\n",
    "\n",
    "    queue = PriorityQueue()\n",
    "    count_u = {node: 0 for node in G_rev.nodes}\n",
    "    tie_breaker = count()  # to avoid error when 2 dep_time are equal, because cannot compare path dictionnaries, so need a tie breaker\n",
    "\n",
    "    # Each item in the queue: (neg_time, tie breaker,  current_stop, path_so_far)\n",
    "    # Start from target with an empty path\n",
    "    queue.put((-latest_arrival_time_min, next(tie_breaker), target_stop, []))\n",
    "\n",
    "    while not queue.empty():\n",
    "        current_time_neg, _, current_stop, path_so_far = queue.get()\n",
    "        current_time = -current_time_neg\n",
    "\n",
    "        if count_u[current_stop] >= expand_max:\n",
    "            continue  # Skip node if already expanded k times\n",
    "\n",
    "        # We only interested in paths that start at start_stop\n",
    "        if current_stop == start_stop:\n",
    "            top_k_paths.add_path(current_stop, path_so_far)\n",
    "        \n",
    "        count_u[current_stop] += 1\n",
    "\n",
    "        for _, neighbor, key, edge_data in G_rev.out_edges(current_stop, keys=True, data=True):\n",
    "            edge_type = edge_data.get('edge_type', 'transit')\n",
    "\n",
    "            if edge_type == 'transit':\n",
    "                dep_time = edge_data['dep_time_min']\n",
    "                arr_time = edge_data['arr_time_min']\n",
    "                if arr_time <= current_time:\n",
    "                    leg = {\n",
    "                        'from': neighbor,\n",
    "                        'to': current_stop,\n",
    "                        'dep_time_min': dep_time,\n",
    "                        'arr_time_min': arr_time,\n",
    "                        'trip_id': edge_data.get('trip_id'),\n",
    "                        'type': 'transit'\n",
    "                    }\n",
    "                    new_path = path_so_far + [leg]\n",
    "                    queue.put((-dep_time, next(tie_breaker), neighbor, new_path))\n",
    "\n",
    "            elif edge_type in ['transfer', 'distance']:\n",
    "                duration = edge_data.get('min_transfer_time') or edge_data.get('duration') or 2\n",
    "                dep_time = current_time - duration\n",
    "                leg = {\n",
    "                    'from': neighbor,\n",
    "                    'to': current_stop,\n",
    "                    'dep_time_min': dep_time,\n",
    "                    'arr_time_min': current_time,\n",
    "                    'trip_id': None,\n",
    "                    'type': edge_type\n",
    "                }\n",
    "                new_path = path_so_far + [leg]\n",
    "                queue.put((-dep_time, next(tie_breaker), neighbor, new_path))\n",
    "\n",
    "    return top_k_paths.get_k_top_paths(node=start_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b88bf3a2-22d9-441b-8aa4-23db4b8d6388",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Format dep/arr times in minutes into HH:MM strings \"\"\"\n",
    "def minutes_to_time_str(minutes):\n",
    "    if pd.isna(minutes) or minutes == float('-inf') or minutes == float('inf'):\n",
    "        return \"\"\n",
    "    h = int(minutes) // 60\n",
    "    m = int(minutes) % 60\n",
    "    return f\"{h:02}:{m:02}\"\n",
    "\n",
    "\n",
    "def time_to_minutes(t):\n",
    "    return t.hour * 60 + t.minute"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b565eaf9-2198-4683-8b06-6767d462b330",
   "metadata": {},
   "source": [
    "# 6 - Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9c85c-63bd-4042-8e9c-1d65d7e23ae2",
   "metadata": {},
   "source": [
    "## 6.1 - Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68646f6b-ee6a-4cb6-8806-36d183ce16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_route_df(path):\n",
    "    \"\"\"\n",
    "    Converts a routing path into a DataFrame of readable segments.\n",
    "    Each row represents a movement (leg) from one stop to the next.\n",
    "    \n",
    "    Parameters:\n",
    "    path (list of dict): A list representing a sequence of legs (from reverse_routing_algo_top_k).\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A structured DataFrame of the route.\n",
    "    \"\"\"\n",
    "    df_list = []\n",
    "\n",
    "    for i, step in enumerate(reversed(path)):  # reverse to show forward direction\n",
    "        leg_type = step['type']\n",
    "        dep_min = step[\"dep_time_min\"]\n",
    "        arr_min = step[\"arr_time_min\"]\n",
    "        duration = arr_min - dep_min if \"duration\" not in step else step[\"duration\"]\n",
    "        trip_id = step.get(\"trip_id\", \"\")\n",
    "\n",
    "        df_list.append({\n",
    "            \"step\": i + 1,\n",
    "            \"leg_type\": leg_type,\n",
    "            \"from_stop_id\": step[\"from\"],\n",
    "            \"to_stop_id\": step[\"to\"],\n",
    "            \"dep_time\": minutes_to_time_str(dep_min),\n",
    "            \"arr_time\": minutes_to_time_str(arr_min),\n",
    "            \"duration\": duration,\n",
    "            \"trip_id\": trip_id,\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbf3066e-10dc-4d98-b404-2578ed213849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_merges(df):\n",
    "    # Merge with trip_names_df (assumed to contain 'trip_id', 'route_desc', 'leg_type') \n",
    "    df = df.merge(trip_names_df, on='trip_id', how='left')\n",
    "    \n",
    "    # First merge to get info for from_stop_id\n",
    "    df_merged = df.merge(sbb_stops_region, left_on='from_stop_id', right_on='stop_id_cleaned', how='left') \\\n",
    "    .rename(columns={\n",
    "        'stop_name': 'from_stop_name',\n",
    "        'stop_lat': 'from_lat',\n",
    "        'stop_lon': 'from_lon'\n",
    "    }).drop(columns=['stop_id_cleaned'])\n",
    "    \n",
    "    # Second merge to get info for to_stop_id\n",
    "    df_merged = df_merged.merge(sbb_stops_region, left_on='to_stop_id', right_on='stop_id_cleaned', how='left') \\\n",
    "    .rename(columns={\n",
    "        'stop_name': 'to_stop_name',\n",
    "        'stop_lat': 'to_lat',\n",
    "        'stop_lon': 'to_lon'\n",
    "    }).drop(columns=['stop_id_cleaned'])\n",
    "\n",
    "    df_merged['route_short_name'] = df_merged['route_short_name'].fillna('walk')\n",
    "\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcb1b0c8-2a98-45ed-a43b-54c963af20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_emojis(df):\n",
    "    \"\"\"\n",
    "    Input: a DataFrame from create_route_df() and prepare_merges().\n",
    "    Adds two columns:\n",
    "        - 'emoji': a visual indicator of the transport type\n",
    "        - 'transport_name': a readable label for the mode\n",
    "    \"\"\"\n",
    "\n",
    "    transport_emojis = {\n",
    "        \"walk\": (\"🚶🏽‍♀️\", \"Walk\"),\n",
    "        \"transfer\": (\"🔁\", \"Direct Transfer\"),\n",
    "        \"B\": (\"🚌\", \"Bus\"),\n",
    "        \"M\": (\"Ⓜ️\", \"Metro\"),\n",
    "        \"RE\": (\"🚉\", \"RegioExpress\"),\n",
    "        \"IR\": (\"🚄\", \"InterRegio\"),\n",
    "        \"IC\": (\"🚅\", \"InterCity\"),\n",
    "        \"R\": (\"🚉\", \"Regio\")\n",
    "    }\n",
    "\n",
    "    # Define a function to extract emoji and name\n",
    "    def get_emoji_name(row):\n",
    "        key = row.get('route_desc') or row.get('leg_type')\n",
    "        if key in transport_emojis:\n",
    "            return transport_emojis[key]\n",
    "        elif row.get('leg_type') in transport_emojis:\n",
    "            return transport_emojis[row['leg_type']]\n",
    "        else:\n",
    "            return (\"❓\", key if key else \"Unknown\")\n",
    "\n",
    "    # Apply row-wise\n",
    "    df[['emoji', 'transport_name']] = df.apply(lambda row: pd.Series(get_emoji_name(row)), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790db98-a638-43b0-be03-afa6d2980788",
   "metadata": {},
   "source": [
    "## 6.2 - Visualization interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "92441903-611c-4e38-b847-195dbb478c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f919b625dfe4632a60b1fe81a65c533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Start stop', options=('Bussigny, Buyère', 'Bussigny, Cocagne', 'Bu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import Dropdown, IntSlider, Button, HBox, VBox, Output, Layout\n",
    "from IPython.display import display\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import datetime\n",
    "\n",
    "# Create widgets\n",
    "start_stop_dd   = Dropdown(options=unique_stop_names, description='Start stop')\n",
    "end_stop_dd     = Dropdown(options=unique_stop_names, description='End stop')\n",
    "arrival_hour_sl = IntSlider(min=0, max=23, value=18, description='Arrival hour')\n",
    "arrival_min_sl  = IntSlider(min=0, max=59, value=0,  description='Arrival min')\n",
    "weather_dd      = Dropdown(options=['Clear', 'Rain'], description='Weather')\n",
    "Q_sl            = IntSlider(\n",
    "    min=0, max=100, value=80, step=1,\n",
    "    description='Min confidence (%)',\n",
    "    style={'description_width': '200px'},\n",
    "    layout=Layout(width='400px')\n",
    ")\n",
    "k_sl            = IntSlider(\n",
    "    min=1, max=10, value=1,\n",
    "    description='How many possible paths?',\n",
    "    style={'description_width': '200px'},\n",
    "    layout=Layout(width='400px')\n",
    ")\n",
    "path_ix_sl      = IntSlider(\n",
    "    min=0, max=9, value=0,\n",
    "    description='Show path #',\n",
    "    style={'description_width': '200px'},\n",
    "    layout=Layout(width='400px')\n",
    ")\n",
    "\n",
    "# Create Button and Output area\n",
    "submit_btn = Button(description='Submit', button_style='primary')\n",
    "out        = Output()\n",
    "\n",
    "# Define callback for the button\n",
    "def on_submit(b):\n",
    "    out.clear_output()\n",
    "    with out:\n",
    "        print(\"Working…\")\n",
    "\n",
    "        start_stop = start_stop_dd.value\n",
    "        end_stop   = end_stop_dd.value\n",
    "\n",
    "        if start_stop == end_stop:\n",
    "            out.clear_output()\n",
    "            print(\"❌ The start and end stop must be different.\")\n",
    "            print(\"Done\")\n",
    "            return\n",
    "\n",
    "        arrival_hour      = arrival_hour_sl.value\n",
    "        arrival_minute    = arrival_min_sl.value\n",
    "        weather_condition = weather_dd.value\n",
    "        Q                 = Q_sl.value\n",
    "        k                 = k_sl.value\n",
    "        path_index        = path_ix_sl.value\n",
    "\n",
    "        if path_index >= k:\n",
    "            out.clear_output()\n",
    "            print(f\"❌ You asked to show path #{path_index}, but you only requested {k} paths.\")\n",
    "            print(\"Done\")\n",
    "            return\n",
    "\n",
    "        # Convert stop names to IDs\n",
    "        start_stop_id = sbb_stops_region.loc[\n",
    "            sbb_stops_region['stop_name'] == start_stop, 'stop_id_cleaned'\n",
    "        ].iloc[0]\n",
    "        end_stop_id = sbb_stops_region.loc[\n",
    "            sbb_stops_region['stop_name'] == end_stop, 'stop_id_cleaned'\n",
    "        ].iloc[0]\n",
    "\n",
    "        # Build arrival_time\n",
    "        arrival_time = datetime.datetime(\n",
    "            2025, 5, 14, arrival_hour, arrival_minute\n",
    "        )\n",
    "\n",
    "        # Run reverse routing\n",
    "        top_k_paths = reverse_routing_algo_top_k(\n",
    "            G,\n",
    "            start_stop=start_stop_id,\n",
    "            target_stop=end_stop_id,\n",
    "            latest_arrival_time=arrival_time,\n",
    "            score_fn=score_path_by_latest_departure,\n",
    "            confidence_fn=get_confidence,\n",
    "            Q=Q/100,\n",
    "            delay_model=delay_model,\n",
    "            weather_condition=weather_condition,\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        if not top_k_paths:\n",
    "            out.clear_output()\n",
    "            print(\"❌ No path found with sufficient confidence.\")\n",
    "            print(\"Done\")\n",
    "            return\n",
    "\n",
    "        num_found = len(top_k_paths)\n",
    "        warning_text = None\n",
    "        if num_found < k:\n",
    "            warning_text = f\"⚠️ Only {num_found} paths found (requested {k}).\"\n",
    "\n",
    "        if path_index >= num_found:\n",
    "            out.clear_output()\n",
    "            print(f\"❌ Only {num_found} paths found.\")\n",
    "            print(\"Done\")\n",
    "            return\n",
    "\n",
    "        # Build & display the chosen path\n",
    "        path_df = create_route_df(top_k_paths[path_index][0])\n",
    "        path_df = prepare_merges(path_df)\n",
    "        path_df = add_emojis(path_df)\n",
    "\n",
    "        out.clear_output()\n",
    "        if warning_text:\n",
    "            print(warning_text)\n",
    "        print(\"Done\")\n",
    "\n",
    "        # Plot departure points\n",
    "        fig = px.scatter_mapbox(\n",
    "            path_df,\n",
    "            lat='from_lat',\n",
    "            lon='from_lon',\n",
    "            hover_name='from_stop_name',\n",
    "            hover_data={\n",
    "                'trip_id': True,\n",
    "                'leg_type': True,\n",
    "                'dep_time': True,\n",
    "                'arr_time': True,\n",
    "                'transport_name': True\n",
    "            },\n",
    "            zoom=11,\n",
    "            mapbox_style='carto-positron',\n",
    "            title=(\n",
    "                f\"Route from {start_stop} to {end_stop} \"\n",
    "                f\"(arrive by {arrival_hour:02}:{arrival_minute:02})\"\n",
    "            ),\n",
    "            width=1200,\n",
    "            height=700 \n",
    "        )\n",
    "\n",
    "        # Draw edges\n",
    "        shown_routes = set()\n",
    "        for _, row in path_df.iterrows():\n",
    "            route_name = row['route_short_name']\n",
    "            color = 'royalblue' if row['leg_type']=='transit' else 'orange'\n",
    "            hover_text = (\n",
    "                f\"{row['from_stop_name']} → {row['to_stop_name']}<br>\"\n",
    "                f\"Mode: {row['transport_name']} {row['emoji']}<br>\"\n",
    "                f\"Line: {route_name}<br>\"\n",
    "                f\"Trip ID: {row['trip_id'] or '—'}<br>\"\n",
    "                f\"Dep: {row['dep_time']} | Arr: {row['arr_time']}<br>\"\n",
    "            )\n",
    "            show_legend = route_name not in shown_routes\n",
    "            if show_legend:\n",
    "                shown_routes.add(route_name)\n",
    "\n",
    "            fig.add_trace(go.Scattermapbox(\n",
    "                lat=[row['from_lat'], row['to_lat']],\n",
    "                lon=[row['from_lon'], row['to_lon']],\n",
    "                mode='lines',\n",
    "                line=dict(width=4, color=color),\n",
    "                hoverinfo='text',\n",
    "                text=[hover_text],\n",
    "                name=route_name if show_legend else None,\n",
    "                showlegend=show_legend\n",
    "            ))\n",
    "\n",
    "        # End marker\n",
    "        last_row = path_df.iloc[-1]\n",
    "        fig.add_trace(go.Scattermapbox(\n",
    "            lat=[last_row['to_lat']],\n",
    "            lon=[last_row['to_lon']],\n",
    "            mode='markers',\n",
    "            marker=dict(size=12, color='red'),\n",
    "            name='End',\n",
    "            hovertext=f\"End: {last_row['to_stop_name']}\",\n",
    "            hoverinfo='text'\n",
    "        ))\n",
    "\n",
    "        display(fig)\n",
    "\n",
    "\n",
    "# Wire up the callback\n",
    "submit_btn.on_click(on_submit)\n",
    "\n",
    "# Layout and display\n",
    "controls = VBox([\n",
    "    HBox([start_stop_dd, end_stop_dd]),\n",
    "    HBox([arrival_hour_sl, arrival_min_sl]),\n",
    "    weather_dd,\n",
    "    Q_sl,\n",
    "    k_sl,\n",
    "    path_ix_sl,\n",
    "    submit_btn\n",
    "])\n",
    "display(controls, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d760d3-01fa-409b-b07b-8e3164dc22d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e2c1f-af90-4e38-ad47-08333d18098d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
