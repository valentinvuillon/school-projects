{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "### Préparation de l'environnement\n",
    "\n",
    "* Importe la donnée Carbosense curated\n",
    "* Import les packages pythons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git lfs pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Lire la donnée dans une DataFrame pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = '../data/carbosense-curated/CarboSense-October2017_curated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Location_Name.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "Pour les experts métier, nous savons qu'il existe une relation entre le niveau de CO2, la temperature, l'humidity, l'heure et l'emplacement géographique.\n",
    "\n",
    "Pouvons nous estimer le niveau de CO2 à partir de la température $T$, l'Humidité $H$ et l'heure de la journée $t$ for en capteur donné? c.a.d trouver la a function $\\hat{f}$:\n",
    "$$CO2 \\sim f(T, H, t)$$\n",
    "\n",
    "- Température - numerique\n",
    "- Humidity - numerique\n",
    "- Heure - numérique\n",
    "\n",
    "Méthode:\n",
    "\n",
    "- Modèle d'arbre de régression évalué par Erreur de Moyenne Absolue (MAE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**mean absolute error (MAE)**:\n",
    "$$\\mathrm {MAE} ={\\frac {1}{n} \\sum _{i=1}^{n}\\left|\\hat{y}_{i}-y_{i}\\right|},$$ where $\\hat{y}_{i}$ is the prediction and $y_{i}$ the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "Nous convertissons les timestamp en moments de la journée alignés sur chaque 30min (création d'une nouvelle variable)\n",
    "\n",
    "0:  00:00\\\n",
    "1:  00:30\\\n",
    "2:  01:00\\\n",
    "...\\\n",
    "47: 23:30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timenum'] = df['Timestamp'].dt.hour * 2 + df['Timestamp'].dt.minute // 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Reconstruire le CO2 à partir de la température, humidité, heure de la journée\n",
    "\n",
    "Nous allons essayer différent modèles. De manière à ne pas répéter du code nous créons une fonction qui:\n",
    "\n",
    "- Découpe les données **df** en ensemble d'apprentissage (X_train, Y_train) et un ensemble de test (X_test, Y_test)\n",
    "- Apprentissage du modèle en utilisant la méthode **model** (argument) sur les données d'apprentissage\n",
    "- Évaluation du modèle avec les données de test à l'aide de la métrique **measure** (MAE)\n",
    "- Visualisation du modèle sous forme de serie séquentielle sur l'interval X_train + X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_plot(df, model, measure, split_date='2017-10-25'):\n",
    "    \"\"\"\n",
    "    Apprend, test et affiche\n",
    "    \"\"\"\n",
    "    \n",
    "    X = df[['T', 'H', 'timenum']]\n",
    "    y = df['CO2']\n",
    "    \n",
    "    # Echantillons d'apprentissage: toutes les données avant split_date\n",
    "    X_train = X[df['Timestamp'] < split_date]\n",
    "    y_train = y[df['Timestamp'] < split_date]\n",
    "    \n",
    "    # Echantillons de test toutes les données après the split_date\n",
    "    X_test = X[df['Timestamp'] >= split_date]\n",
    "    y_test = y[df['Timestamp'] >= split_date]\n",
    "    \n",
    "    # Apprentissage du modèle\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluation du modèle\n",
    "    y_train_predict = model.predict(X_train)\n",
    "    train_err = measure(y_train, y_train_predict)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    test_err = measure(y_test, y_test_predict)\n",
    "    \n",
    "    print(f'Erreur Aprentissage: {train_err:.2f}, Erreur Test: {test_err:.2f}')\n",
    "    \n",
    "    # Affichage\n",
    "    y_predict = np.append(y_train_predict, y_test_predict)\n",
    "\n",
    "    plt.subplots(figsize=(20, 5))\n",
    "    plt.plot(df.Timestamp, y, label = 'Vraie')\n",
    "    plt.plot(df.Timestamp, y_predict, label = 'Prédite')\n",
    "    plt.vlines(pd.Timestamp(split_date), ymin=df.CO2.min(), ymax=df.CO2.max(), colors='k', linestyles= 'dashed')\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"CO2/ppm\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "#### Tentative 1\n",
    "\n",
    "Utiliser un arbre de regression (DecisionTreeRegressor) pour reconstruire les valeurs de CO2 du capteur WRTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[df.Location_Name == 'WRTW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(criterion='mae')\n",
    "model = train_plot(df_model, tree, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cet arbre de régression un défaut de sur-apprentissage (Erreur d'apprentissage 0, erreur de prediction importante).\n",
    "\n",
    "Car nous lui avont permis de grandir sans contrainte et l'algorithm a trouvé une solution très spécifique à la donnée d'apprentissage, mais qui ne se généralise pas aux autres échantillons.\n",
    "\n",
    "Il est possible de vérifier la forme de l'arbre et de voir qu'il est bien balancé et profond. Pour chaque combinaison $(T,H,t)$ des données d'apprentissage il est sans doute capable de trouver la réponse exacte ou très proche du $CO_2$ correspondante à cette combinaison dans les données d'apprentissage. Mais il n'est pas aussi performant pour les combinaisons de $(T,H,t)$ des données de test, qui lui étaient inconnues au moment de l'apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(30,10))\n",
    "plot_tree(model,max_depth=4,feature_names=['T','H','timenum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "#### Tentative 2\n",
    "\n",
    "Nous corrigeons le problème de sur-apprentissage avec **un élagage et cross-validation en blocs de 5**:\n",
    "\n",
    "Pour ce faire, voir les hyperparamètres de [**DecisionTreeRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html):\n",
    "\n",
    "- **max_depth**: profondeur maxinun de l'arbre (c.a.d distance maximum entre le noeud de départ (racine) et les noeuds de terminaison\n",
    "- **min_samples_split**: le nombre minimum d'échantillons requis pour diviser un noeud interne en sous noeuds.\n",
    "- **min_samples_leaf**: le nombre minimum de sample requis pour être un noeud de terminaison\n",
    "- ....\n",
    "\n",
    "Nous essayons 4 valeurs de max_depth et 5 valeurs de min_samples_split (donc $4*5=20$ combinaisons possible).\n",
    "\n",
    "De manière à automatiser la recherche nous [**GridSearchCV**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), qui va essayer les 20 combinaisons possibles d'hyperparamètres pour apprendre des modèles de regression arborescents et les comparer.\n",
    "\n",
    "La méthode retourne parmis ces modèles celui qui la meilleur performance, en utilisant la métrique de l'argument **scoring**. Nous utilisons **neg_mean_absloute_error** ($-MAE$), car GridSearchCV essaye d'augmenter cette métrique alors que nous voulons la diminuer.\n",
    "\n",
    "GridSearchCV valide les modèles qu'il obtient avec la méthode de Validation Croisée. L'argument **cv** est le nombre de blocs utilisés pour la validation.\n",
    "\n",
    "**NB 1**: Par défaut les échantillons sont répartis aléatoirement entre les 5 blocs (donc le résultat peut changer à chaque invocation de GridSearchCV). Il est possible d'utiliser KFold pour imposer une stratégie de selection déterministique.\n",
    "\n",
    "**NB 2**: Notez que GridSearchCV expose l'interface fit, et predict des modèles. La fonction train_plot ne fait pas la différence entre un objet de type DecisionTreeRegressor ou un objet de type GridSearchCV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(criterion='mae')\n",
    "\n",
    "# Grille d'hyperparamètres à utiliser\n",
    "param_grid = dict(\n",
    "    max_depth=range(5, 21, 5),          # 5, 10, 15, 20\n",
    "    min_samples_split=range(10, 51, 10) # 10, 20, 30, 40, 50\n",
    ")\n",
    "\n",
    "# Utiliser la Validation Croisée avec MAE\n",
    "# Attention, GridSearchCV va essayer de maximiser la valeur, nous utilisons\n",
    "# donc la moyenne d'erreur absolue MAE négative (minimisation)\n",
    "tree_cv = GridSearchCV(\n",
    "    tree,\n",
    "    param_grid,\n",
    "    cv = 5, # 5 blocs\n",
    "    #cv = KFold(n_splits=5, shuffle=False),\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "tree_cv=train_plot(df_model, tree_cv, mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous constatons une amélioration visible de l'erreur de prédiction, ainsi qu'une augmentation de l'erreur d'apprentissage.\n",
    "\n",
    "Il est possible de vérifier que l'arbre est beaucoup moins complexe que celui appris sans jouer avec les hyperparamètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(30,10))\n",
    "plot_tree(tree_cv.best_estimator_,max_depth=12,feature_names=['T','H','timenum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Exercices\n",
    "\n",
    "Reprendre le premier exemple de la tentative 1 pour construire un modèle de régression avec le type de modèle de [**RandomForestRegressor**](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) de scikit-learn.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Bonus\n",
    "\n",
    "Détection de valeurs anormales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kbrl = df[df.Location_Name == 'KBRL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kbrl.plot('Timestamp', 'CO2', figsize=(20, 5))\n",
    "plt.annotate('Outlier', size=12,\n",
    "             xy = ('2017-10-05 07:00:00', 727.537201), \n",
    "             xytext = ('2017-10-06 07:00:00', 700), \n",
    "             arrowprops=dict(arrowstyle='fancy'))\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"CO2/ppm\")\n",
    "plt.grid(True, which=\"minor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_kbrl[['T', 'H', 'timenum']]\n",
    "y = df_kbrl['CO2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(criterion='mae')\n",
    "tree.fit(X, y)\n",
    "\n",
    "df_kbrl=df_kbrl.assign(CO2_predict=tree.predict(X))\n",
    "df_kbrl.plot('Timestamp', ['CO2', 'CO2_predict'], \n",
    "             figsize=(20, 5), title = 'Apprentissage aggressif sans validation croisée')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"CO2/ppm\")\n",
    "plt.grid(True, which=\"minor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(30,10))\n",
    "plot_tree(tree,max_depth=3,feature_names=['T','H','timenum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous voulons capturer le comportement **général** des niveaux de CO2 mas pas les outliers, donc il est important d'éviter que le sur-apprentissage. La validation croisée s'occupe de ça."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeRegressor(criterion='mae')\n",
    "\n",
    "param_grid = dict(\n",
    "    max_depth=range(5, 21, 5), \n",
    "    min_samples_split=range(10, 51, 10)\n",
    ")\n",
    "\n",
    "tree_cv = GridSearchCV(\n",
    "    tree, \n",
    "    param_grid, \n",
    "    cv = 5,\n",
    "    scoring='neg_mean_absolute_error'\n",
    ")\n",
    "\n",
    "tree_cv.fit(X, y)\n",
    "\n",
    "df_kbrl = df_kbrl.assign(CO2_predict=tree_cv.predict(X))\n",
    "df_kbrl.plot('Timestamp', ['CO2', 'CO2_predict'], \n",
    "             figsize=(20, 5), title = 'Apprentissage avec validation croisée')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"CO2/ppm\")\n",
    "plt.grid(True, which=\"minor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(30,10))\n",
    "plot_tree(tree_cv.best_estimator_,max_depth=10,feature_names=['T','H','timenum'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
